# =====================================
# GRAPHITI MCP MULTI-ENGINE CONFIGURATION
# =====================================

# Neo4j Database Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# =====================================
# LLM CONFIGURATION
# =====================================

# LLM Engine Selection (openai|anthropic|gemini|azure_openai)
LLM_ENGINE=gemini
# Available models per engine:
# - openai: gpt-4.1-mini, gpt-4.1-nano, gpt-4o, etc.
# - anthropic: claude-sonnet-4-20250514, claude-3-haiku-20240307, etc.
# - gemini: gemini-2.5-pro, gemini-2.5-flash
# - azure_openai: (deployment names)

# Primary LLM Model
MODEL_NAME=gemini-2.5-flash
# Small/Fast LLM Model (for simple tasks)
SMALL_MODEL_NAME=gemini-2.5-flash

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic Configuration  
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Gemini Configuration
GOOGLE_API_KEY=your_google_ai_studio_api_key_here

# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=your_azure_endpoint
AZURE_OPENAI_API_VERSION=2025-01-01-preview
AZURE_OPENAI_DEPLOYMENT_NAME=your_deployment_name
AZURE_OPENAI_USE_MANAGED_IDENTITY=false

# =====================================
# EMBEDDING CONFIGURATION  
# =====================================

# Embedding Engine Selection (openai|vertex_ai|gemini|azure_openai|dual)
EMBEDDING_ENGINE=dual
# Available models per engine:
# - openai: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
# - vertex_ai: text-embedding-005
# - gemini: gemini-embedding-exp-03-07, text-embedding-004
# - dual: uses both vertex_ai + gemini for comparison

# Primary Embedding Model
EMBEDDER_MODEL_NAME=text-embedding-005
# Secondary Embedding Model (for dual mode)
SECONDARY_EMBEDDER_MODEL_NAME=gemini-embedding-exp-03-07

# Vertex AI Configuration (for text-embedding-005)
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
GOOGLE_CLOUD_PROJECT=your_project_id
GOOGLE_CLOUD_LOCATION=us-central1

# Gemini API Configuration (for gemini-embedding-exp-03-07)
# Uses same GOOGLE_API_KEY as LLM

# Azure OpenAI Embeddings
AZURE_OPENAI_EMBEDDING_ENDPOINT=your_azure_endpoint
AZURE_OPENAI_EMBEDDING_API_VERSION=2023-05-15
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=your_embedding_deployment

# =====================================
# DUAL-ENGINE SPECIFIC CONFIGURATION
# =====================================

# Dual Engine Strategy (primary|fallback|comparison|round_robin)
DUAL_ENGINE_STRATEGY=comparison
# - primary: Use primary engine, fallback to secondary on failure
# - fallback: Same as primary but with logging
# - comparison: Use both engines and compare results
# - round_robin: Alternate between engines

# Task Type Optimization
ENABLE_TASK_TYPE_OPTIMIZATION=true
# Automatically select CODE_RETRIEVAL_QUERY for code-related queries

# Performance Settings
EMBEDDING_TIMEOUT_SECONDS=30
ENABLE_EMBEDDING_CACHING=true
MAX_CONCURRENT_EMBEDDINGS=5

# =====================================
# GENERAL SETTINGS
# =====================================

# Group ID for namespacing
GROUP_ID=pepo_phd_research

# Temperature settings
LLM_TEMPERATURE=0.0

# Concurrency limits  
SEMAPHORE_LIMIT=10

# Logging level (DEBUG|INFO|WARNING|ERROR)
LOG_LEVEL=INFO
